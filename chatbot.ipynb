{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ssl\n",
    "# ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!arch -arm64 brew install portaudio\n",
    "#!arch -arm64 brew link portaudio\n",
    "\n",
    "#!pip uninstall pyaudio --y\n",
    "\n",
    "#!pip3 install --no-cache-dir --global-option='build_ext' --global-option='-I/opt/homebrew/Cellar/portaudio/19.7.0/include' --global-option='-L/opt/homebrew/Cellar/portaudio/19.7.0/lib' pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def record_audio(time_seconds):\n",
    "\n",
    "    chunk = 1024  # Record in chunks of 1024 samples\n",
    "    sample_format = pyaudio.paInt16  # 16 bits per sample\n",
    "    channels = 1\n",
    "    fs = 48000  # Record at 44100 samples per second\n",
    "    filename = \"output.wav\"\n",
    "\n",
    "    p = pyaudio.PyAudio()  # Create an interface to PortAudio\n",
    "\n",
    "    seconds = time_seconds\n",
    "\n",
    "    print('Recording')\n",
    "\n",
    "    stream = p.open(format=sample_format,\n",
    "                    channels=channels,\n",
    "                    rate=fs,\n",
    "                    frames_per_buffer=chunk,\n",
    "                    input=True)\n",
    "\n",
    "    frames = []  # Initialize array to store frames\n",
    "\n",
    "    # Store data in chunks for 3 seconds\n",
    "    for i in range(0, int(fs / chunk * seconds)):\n",
    "        data = stream.read(chunk)\n",
    "        frames.append(data)\n",
    "\n",
    "    # Stop and close the stream \n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    # Terminate the PortAudio interface\n",
    "    p.terminate()\n",
    "\n",
    "    print('Finished recording')\n",
    "\n",
    "    # Save the recorded data as a WAV file\n",
    "    wf = wave.open(filename, 'wb')\n",
    "    wf.setnchannels(channels)\n",
    "    wf.setsampwidth(p.get_sample_size(sample_format))\n",
    "    wf.setframerate(fs)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install git+https://github.com/openai/whisper.git "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "whisper_model = whisper.load_model(\"small.en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# device = \"mps\" if  torch.backends.mps.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_text(model,path):\n",
    "    result = model.transcribe(path)\n",
    "    print('voice processed')\n",
    "    return(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "def texttospeech(text_input):\n",
    "    pyobj = pyttsx3.init()\n",
    "    pyobj.setProperty('rate', 100) \n",
    "    pyobj.say(text_input)\n",
    "    pyobj.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "texttospeech(\"My name is bot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, BlenderbotForConditionalGeneration\n",
    "\n",
    "mname = \"facebook/blenderbot-400M-distill\"\n",
    "model = BlenderbotForConditionalGeneration.from_pretrained(mname)\n",
    "tokenizer = AutoTokenizer.from_pretrained(mname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(UTTERANCE):\n",
    "    print(\"Human: \", UTTERANCE)\n",
    "\n",
    "    inputs = tokenizer([UTTERANCE], return_tensors=\"pt\")\n",
    "    reply_ids = model.generate(**inputs)\n",
    "    reply = tokenizer.batch_decode(reply_ids, skip_special_tokens=True)[0]\n",
    "    print(\"Bot: \", reply )\n",
    "    return reply\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording\n",
      "Finished recording\n",
      "voice processed\n",
      "Human:   Hi my name is Puneet. How are you doing?\n",
      "Bot:   Hi, Punet! I'm doing well, thank you. How about yourself? \n",
      "Recording\n",
      "Finished recording\n",
      "voice processed\n",
      "Human:   I am doing great, just giving a presentation to my class.\n",
      "Bot:   That's great! What kind of presentation is it? I'm sure you'll do great!\n",
      "Recording\n",
      "Finished recording\n",
      "voice processed\n",
      "Human:   I am just showing a model I built.\n",
      "Bot:   That's awesome! What kind of model is it? Is it your first time doing it?\n",
      "Recording\n",
      "Finished recording\n",
      "voice processed\n",
      "Human:   Yeah, I have practiced a lot but yeah this is the first\n",
      "Bot:   Good luck! I'm sure you'll do just fine. What are you practicing for?\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    record_audio(5)\n",
    "    UTTERANCE = audio_to_text(whisper_model,\"output.wav\")\n",
    "    reply = chat(UTTERANCE)\n",
    "    texttospeech(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "174b908828a95327d8a80a972e6010943b4d74829279f8ab86932c037d75785c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
